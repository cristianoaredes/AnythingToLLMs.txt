<div align="center">

# üìÑ ‚û°Ô∏è üß† Anything to LLMs.txt

<!-- Status do Projeto -->
[![Status](https://img.shields.io/badge/status-WIP-yellow?style=flat-square)](https://github.com/cristianocosta/anything-to-llms-txt)
[![Licen√ßa](https://img.shields.io/badge/licen√ßa-MIT-blue?style=flat-square)](LICENSE)
[![Status de Build](https://img.shields.io/github/actions/workflow/status/cristianocosta/anything-to-llms-txt/ci.yml?branch=main&style=flat-square&logo=github-actions&logoColor=white)](https://github.com/cristianocosta/anything-to-llms-txt/actions)

<!-- Tecnologia -->
[![Python](https://img.shields.io/badge/python-3.11%2B-blue?style=flat-square&logo=python&logoColor=white)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.95%2B-009688?style=flat-square&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/docker-ready-2496ED?style=flat-square&logo=docker&logoColor=white)](https://www.docker.com/)

<!-- Recursos -->
[![LLM Ready](https://img.shields.io/badge/LLM-ready-green?style=flat-square&logo=openai&logoColor=white)](https://github.com/cristianocosta/anything-to-llms-txt)
[![Suporte OCR](https://img.shields.io/badge/OCR-suportado-blueviolet?style=flat-square)](https://github.com/cristianocosta/anything-to-llms-txt)
[![Formatos](https://img.shields.io/badge/formatos-PDF%20|%20DOCX%20|%20HTML%20|%20TXT-lightgrey?style=flat-square)](https://github.com/cristianocosta/anything-to-llms-txt)

<!-- Comunidade -->
[![Issues](https://img.shields.io/github/issues/cristianocosta/anything-to-llms-txt?style=flat-square&logo=github)](https://github.com/cristianocosta/anything-to-llms-txt/issues)
[![PRs](https://img.shields.io/github/issues-pr/cristianocosta/anything-to-llms-txt?style=flat-square&logo=git)](https://github.com/cristianocosta/anything-to-llms-txt/pulls)
[![Stars](https://img.shields.io/github/stars/cristianocosta/anything-to-llms-txt?style=flat-square&logo=github)](https://github.com/cristianocosta/anything-to-llms-txt/stargazers)

</div>

> **Conversor universal de documentos para o formato estruturado LLMs.txt, otimizado para uso com Grandes Modelos de Linguagem (LLMs).**
>
> ‚ö†Ô∏è **Este projeto √© um Trabalho em Andamento (WIP).** Os recursos podem mudar e algumas funcionalidades podem estar incompletas.

---

## ‚ú® Vis√£o Geral

Anything to LLMs.txt transforma documentos em PDF, DOCX, HTML, TXT e outros formatos em arquivos `.llms.txt` estruturados, prontos para ingest√£o por LLMs. Preserva tabelas, imagens, metadados e oferece perfis de sa√≠da personaliz√°veis, chunking inteligente e an√°lise de tokens.

---

## üì¶ Instala√ß√£o

> ‚ö†Ô∏è **Nota:** Como este √© um projeto em desenvolvimento, a instala√ß√£o e as depend√™ncias podem mudar.

```bash
git clone https://github.com/cristianocosta/anything-to-llms-txt.git
cd anything-to-llms-txt
pip install -r requirements.txt
```

---

## üöÄ In√≠cio R√°pido

```bash
python -m src.main --file data/test_files/example.pdf
```

### Chunking Personalizado

```bash
python -m src.main --file data/test_files/example.pdf --chunk-size 1000 --chunk-overlap 100
```

### Perfis de Sa√≠da

```bash
python -m src.main --file data/test_files/example.pdf --profile llms-tables
```

### An√°lise de Tokens

```bash
python -m src.main --count-tokens output/example.llms.txt --analyze
```

### Processamento em Lote

```bash
python examples/document_analysis_example.py -dir data/test_files -p "*.pdf" -v -b "termos importantes" -c
```

---

## üß© Perfis de Sa√≠da

- `llms-min`: Apenas texto principal
- `llms-ctx`: Texto + contexto m√≠nimo
- `llms-tables`: Inclui tabelas
- `llms-images`: Inclui imagens
- `llms-raw`: Inclui texto bruto
- `llms-full`: Todas as se√ß√µes

---

## üõ†Ô∏è Op√ß√µes e Par√¢metros da CLI

```text
uso: python -m src.main [op√ß√µes]

argumentos opcionais:
  -h, --help            Mostra esta mensagem de ajuda
  --file FILE, -f FILE  Caminho para o arquivo a ser processado
  --no-save, -n         N√£o salva o resultado em um arquivo
  --view, -v            Exibe o conte√∫do completo no terminal
  --chunk-size CHUNK_SIZE
  --chunk-overlap CHUNK_OVERLAP
  --plugins PLUGINS     Plugins Docling (tables,images,raw)
  --pipeline-options PIPELINE_OPTIONS
  --profile {llms-min,llms-ctx,llms-tables,llms-images,llms-raw,llms-full}
  --model-name MODEL_NAME
  --count-tokens FILE
  --analyze, -a
  --verbose, -vb
```

### Op√ß√µes do Exemplo de An√°lise de Documentos

```text
uso: document_analysis_example.py [op√ß√µes]

argumentos opcionais:
  -h, --help                     Mostra esta mensagem de ajuda
  -d, --document DOCUMENT       Caminho para o documento a ser analisado
  -dir, --directory DIRECTORY   Diret√≥rio para processamento em lote de documentos
  -p, --pattern PATTERN         Padr√£o de arquivo para processamento em lote (padr√£o: *.pdf)
  -v, --visualize               Gera visualiza√ß√£o HTML do documento
  -b, --search TEXT             Texto para buscar no documento
  -c, --classify                Classifica imagens no documento
  -s, --output DIRECTORY        Diret√≥rio para salvar resultados (padr√£o: ./results)
  -l, --limit VALUE             Limite de confian√ßa para classifica√ß√£o de imagens (0-1)
```

---

## üóÇÔ∏è Estrutura de Arquivo LLMs.txt

```text
# T√≠tulo: Nome do Documento
# Data: 2025-04-26 10:30:00
# Fonte: caminho/para/arquivo.pdf

# Resumo
Resumo do documento...

# Conte√∫do
Texto principal...

# Tabelas
## Tabela 1
| Coluna 1 | Coluna 2 |
|----------|----------|
| Valor 1  | Valor 2  |

# Imagens
## Imagem 1
Descri√ß√£o da imagem...

# Bruto
Texto bruto...
```

---

## üß∞ Recursos de An√°lise de Documentos

Al√©m de converter para LLMs.txt, o sistema oferece recursos avan√ßados de an√°lise de documentos:

- **Processamento em Lote:** Processa m√∫ltiplos documentos em um diret√≥rio com um √∫nico comando
- **Busca de Texto com Posicionamento:** Localiza termos espec√≠ficos e obt√©m suas coordenadas no documento
- **Classifica√ß√£o de Imagens:** Identifica o conte√∫do das imagens nos documentos
- **Visualiza√ß√£o HTML:** Gera representa√ß√µes visuais interativas dos documentos processados
- **Relat√≥rios Detalhados:** Obt√©m relat√≥rios completos de processamento em lote com m√©tricas e resultados

### Exemplo de Processamento em Lote

```python
from src.tools.document_converter import DocumentConverter

converter = DocumentConverter()
results = converter.process_batch(
    directory="./documents",
    pattern="*.pdf",
    options={
        "visualize": True,
        "search": "intelig√™ncia artificial",
        "classify": True,
        "confidence_threshold": 0.6,
        "output_directory": "./results"
    }
)

# Acessa resultados individuais
for file, result in results.items():
    print(f"Arquivo: {file}, Status: {result['status']}")
    if result.get("search"):
        print(f"  Ocorr√™ncias encontradas: {result['search']['results']}")
```

---

## ü§ñ Detec√ß√£o Autom√°tica de Tipo de Conte√∫do

O sistema identifica automaticamente:

- Artigos cient√≠ficos
- Literatura
- Documentos t√©cnicos
- Conte√∫do educacional
- Documentos legais
- Emails/comunica√ß√£o

Ele sugere o chunking ideal e o modelo LLM para cada caso.

---

## üèóÔ∏è Arquitetura do Sistema (Modelo C4)

A arquitetura do Anything to LLMs.txt foi projetada usando o [modelo C4](https://c4model.com/), fornecendo uma vis√£o clara e multin√≠vel do sistema:

### N√≠vel 1: Contexto do Sistema

```mermaid
flowchart TD
    User([Desenvolvedor/Usu√°rio])
    Admin([Administrador])
    System[Anything to LLMs.txt]
    Docling[(Biblioteca Docling)]
    FileSystem[(Sistema de Arquivos)]
    LLMAPI[(APIs LLM Externas)]
    subgraph "Ecossistema LLM"
        LlamaIndex[(LlamaIndex)]
        LangChain[(LangChain)]
    end
    User -->|"Converte documentos"| System
    Admin -->|"Configura/monitora"| System
    System -->|"Analisa documentos"| Docling
    System -->|"L√™/Escreve"| FileSystem
    System -->|"Valida√ß√£o opcional"| LLMAPI
    System -->|"Exporta dados compat√≠veis"| LlamaIndex
    System -->|"Exporta dados compat√≠veis"| LangChain
```

*Os usu√°rios interagem com o sistema para converter documentos. O sistema depende do Docling para an√°lise, interage com o sistema de arquivos e pode se integrar com APIs LLM e exportar para LlamaIndex/LangChain.*

### N√≠vel 2: Diagrama de Cont√™ineres

```mermaid
flowchart TD
    User([Desenvolvedor/Usu√°rio])
    Admin([Administrador])
    subgraph "Sistema Anything to LLMs.txt"
        CLI[CLI src/main.py]
        API[API REST src/api/]
        WebUI["Interface Web (Planejada)"]
        CoreLib[Biblioteca Principal src/tools/]
        Redis[(Redis)]
        Worker[Worker Ass√≠ncrono]
        Config["Gerenciador de Config (Planejado)"]
    end
    Docling[(Biblioteca Docling)]
    FileSystem[(Sistema de Arquivos)]
    Logging[(Servi√ßo de Logging)]
    User -->|"Usa"| CLI
    User -->|"Usa"| API
    User -->|"Acessa pelo navegador"| WebUI
    Admin -->|"Gerencia"| Config
    Admin -->|"Monitora"| Logging
    CLI -->|"Usa"| CoreLib
    CLI -->|"L√™ config"| Config
    API -->|"Usa"| CoreLib
    API -->|"L√™/Escreve status"| Redis
    API -->|"Delega tarefas"| Worker
    API -->|"L√™ config"| Config
    WebUI -->|"Chama"| API
    Worker -->|"Usa"| CoreLib
    Worker -->|"Usa fila"| Redis
    CoreLib -->|"Usa"| Docling
    CoreLib -->|"L√™/Escreve"| FileSystem
    CoreLib -->|"Reporta status/erros"| Logging
    CoreLib -->|"L√™ config"| Config
```

*O sistema √© modular: CLI, API e workers usam a biblioteca principal. Redis √© usado para gerenciamento de jobs. Interface Web e gerenciador de configura√ß√£o est√£o planejados.*

### N√≠vel 3: Diagrama de Componentes (Biblioteca Principal)

```mermaid
flowchart TD
    API[API REST]
    CLI[CLI]
    subgraph SRC["Biblioteca Principal (src/tools/)"]
        Converter[DocumentConverterTool]
        Formatter[LLMSFormatter]
        Analyzer[TokenAnalyzer]
        Counter[count_tokens]
        Processor[DocumentProcessor]
        Smol[SmolDoclingProcessor]
        OCR["OCRManager (Planejado)"]
        Cache["CacheManager (Planejado)"]
        Plugin["PluginManager (Planejado)"]
        Export["ExportManager (Planejado)"]
        Validation["DocumentValidator (Planejado)"]
    end
    Docling[(Biblioteca Docling)]
    API -->|Usa| Processor
    CLI -->|Usa| Processor
    Processor -->|Valida com| Validation
    Processor -->|Delega para| Converter
    Processor -->|Cache com| Cache
    Converter -->|Usa| Docling
    Converter -->|Formata com| Formatter
    Converter -->|Extrai texto com| OCR
    Converter -->|Otimiza com| Analyzer
    Converter -->|Estende com| Plugin
    Converter -->|Exporta para| Export
    Formatter -->|Conta tokens com| Counter
    Analyzer -->|Usa| Counter
    Export -->|Usa sa√≠da de| Formatter
    OCR -->|Pode ser estendido por| Plugin
    Formatter -->|Pode ser estendido por| Plugin
```

*A biblioteca principal √© altamente modular, com clara separa√ß√£o de responsabilidades e pontos de extensibilidade para recursos futuros.*

### N√≠vel 4: Fluxo de Processamento

```mermaid
sequenceDiagram
    participant User as Usu√°rio
    participant API as Servi√ßo API
    participant Redis as Redis
    participant Worker as Worker
    participant Core as Biblioteca Principal
    participant Docling as Biblioteca Docling
    participant Storage as Armazenamento
    User->>API: 1. Envia documento (POST /api/convert)
    API->>Storage: 2. Armazena documento
    API->>Redis: 3. Cria job (pendente)
    API->>Worker: 4. Submete job
    API->>User: 5. Retorna job_id
    Worker->>Redis: 6. Pega pr√≥ximo job
    Worker->>Storage: 7. Carrega documento
    Worker->>Core: 8. Processa documento
    Core->>Docling: 9. Analisa documento
    Docling-->>Core: Retorna an√°lise
    Core-->>Worker: 10. Retorna doc processado
    Worker->>Storage: 11. Armazena resultado
    Worker->>Redis: 12. Atualiza status (completo)
    User->>API: 13. Verifica status (GET /api/jobs/{id})
    API->>Redis: 14. Obt√©m status do job
    API-->>User: 15. Retorna status + localiza√ß√£o
    User->>Storage: 16. Download do resultado
```

*O sistema usa processamento ass√≠ncrono de jobs para escalabilidade e responsividade, ideal para documentos grandes.*

---

## ‚öôÔ∏è Stack Tecnol√≥gico e Decis√µes de Design

- **FastAPI** para API REST ass√≠ncrona (documenta√ß√£o OpenAPI, valida√ß√£o Pydantic)
- **Redis** para fila de jobs e status
- **Docker** para conteineriza√ß√£o e implanta√ß√£o
- **Docling** para an√°lise robusta de documentos
- **Python Modular** para extensibilidade e testabilidade
- **Workers** para processamento em segundo plano

*A arquitetura foi projetada para modularidade, escalabilidade e extensibilidade.*

---

## üö¶ Roadmap e Pr√≥ximos Passos

Como este √© um **Trabalho em Andamento (WIP)**, estamos desenvolvendo ativamente os seguintes recursos:

- Implementar componentes planejados: PluginManager, ExportManager, CacheManager, DocumentValidator, OCRManager
- Desenvolver Interface Web para uploads e acompanhamento de jobs
- Gerenciador de configura√ß√£o centralizado
- Mais testes automatizados e exemplos de uso avan√ßado
- Integra√ß√£o com mais frameworks LLM
- Otimiza√ß√£o para processamento em lote de grande escala e multi-formato

*Essas melhorias aprimorar√£o as capacidades e experi√™ncia do usu√°rio do sistema. Contribui√ß√µes e feedback s√£o bem-vindos!*

---

## üìö Leitura Adicional e Documenta√ß√£o Completa

> A documenta√ß√£o interna (arquitetura, refer√™ncia da API, guias, changelogs, configura√ß√£o avan√ßada) est√° agora na pasta `docs/`, que n√£o √© rastreada pelo git. Por favor, consulte a documenta√ß√£o interna mais recente em seu espa√ßo de trabalho local.

---

> Feito com ‚ù§Ô∏è para acelerar fluxos de trabalho com LLM e dados complexos!

---

**Resumo:**
Anything to LLMs.txt √© um conversor universal que transforma documentos em um formato estruturado otimizado para LLMs, com suporte a chunking avan√ßado, perfis de sa√≠da, an√°lise de tokens e processamento em lote. F√°cil de instalar, flex√≠vel para usar e pronto para integra√ß√£o em seus fluxos de trabalho de IA.